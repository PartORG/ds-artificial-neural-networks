{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CNN-Architecture-over-a-timeline](https://www.aismartz.com//blog/wp-content/uploads/2019/10/CNN-Architecture-over-a-timeline.jpg)\n",
    "\n",
    "https://www.aismartz.com/blog/cnn-architectures/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ WHAT?\n",
    "    + it is a network which was trained on a large dataset on a large-scale-image classification Task. One can usit as it is for image classification or for transfer learning so we can custumise the model for a new task\n",
    "    \n",
    "+ BENEFITS\n",
    "    + we don't have to train the model\n",
    "    + very easy to incorporate \n",
    "    + fast simulation\n",
    "    + we can achieve very good performaces\n",
    "    \n",
    "+ EXAMPLE\n",
    " + U net: recognize feature on medical images\n",
    " + MobileNet\n",
    " + VGG16/19\n",
    " + ResNet\n",
    " + InceptionV3\n",
    " \n",
    " Most of the pretrained networks available in keras are trained on [1000 different classes](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a) that were used from the [Imagenet](https://www.image-net.org/update-mar-11-2021.php) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, decode_predictions, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image # Keras own inbuild image class\n",
    "from tensorflow.keras.layers import Dense,Dropout,GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Sequential,Input,Model\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets load an image from internet that belong under any of the 1000 classes (few images present in images directory )\n",
    "\n",
    "We will then use a pretrained model (ResNet50) and check the classification result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Information about the other CNN architectures\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/applications\n",
    "\n",
    "\n",
    "https://keras.io/api/applications/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the image as a PIL object and resize to a desired dimension(ideally the same shape as the one which the pretrained model is trained on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img('images/download.jpeg',target_size=(224,224)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert image to array, can also specify datatype\n",
    "img = image.img_to_array(img,dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot image \n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model\n",
    "#### As an example we are using the ResNet50 pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "model = ResNet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#show model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at how many parameters needs to be trained for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check shape required by model\n",
    "model.input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Expand dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape to match the input shape required by the model\n",
    "img = np.expand_dims(img,axis=0) # or img = img.reshape(1,224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape of pred\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode labels\n",
    "decode_predictions(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!! We got the whole result while predicting from our pretrained model !! \n",
    "\n",
    "This brings us to point of applying preprocessing to the image when using pretrained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## why do we need to preprocess image before loading to CNN model ??\n",
    "\n",
    "To get best predictions we need to preprocess the images, just as it was done while the researchers were training them\n",
    "\n",
    "For eg. in Resnet model\n",
    "> The only preprocessing we do is subtracting the mean RGB value, computed on the training set, from each pixel.\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = preprocess_input(img) # preprocess the image in the same method that is used for the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape of pred\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# decode labels\n",
    "decode_predictions(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model now predicts the image accurately after predicting using the preprocessed image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load the `object.png` image from the `imgage` directory and check the results using ResNet50\n",
    "\n",
    "You should be getting the predicted result as `cleaver`\n",
    "\n",
    "Discuss why the model predicted a `phone` as `cleaver`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning for Neural Networks\n",
    "\n",
    "> Transfer learning consists of taking features learned on one problem, and leveraging them on a new, similar problem. For instance, features from a model that has learned to identify racoons may be useful to kick-start a model meant to identify tanukis (japanese racoons).\n",
    "\n",
    "__The benefits of transfer learning are:__\n",
    "* you can reuse pre-trained networks\n",
    "* it saves lots of training time\n",
    "* it allows you to train with very small training datasets\n",
    "\n",
    "__Procedure__\n",
    "1. Take the weights and architecture of a [pre-trained network](https://keras.io/api/applications/)\n",
    "2. Load the \"convolutional base\" of the model (everything except the final dense layers)\n",
    "3. Freeze all the layers of the base (weights become fixed)\n",
    "4. Add a fully connected dense layer on top\n",
    "5. **Add a task specific dense output layer**\n",
    "6. Compile and fit the model to your data\n",
    "\n",
    "<img src='https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Transfer-learning-base-model.jpg?resize=512%2C375&ssl=1'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImageDataGenerator\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "\n",
    "- `class ImageDataGenerator`: Generate batches of tensor image data with **optional** real-time data augmentation\n",
    "\n",
    "This is an efficient way to load data when you are working with lots of image data which does not fit into the memory (RAM) as you can load and train the model in small batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder names containing images of the things you want to classify\n",
    "classes = ['phone','wallet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation can address a variety of challenges when training a CNN model, such as limited or imbalanced data, overfitting, and variation and complexity.  eg Flipping,Rotation, Translation, Scaling ... of images\n",
    "\n",
    "This technique can increase the size of the dataset and balance the classes by applying different transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an image data generator\n",
    "# Data augmentation: Applies random distortions and transformations to the images (only on your training data!).\n",
    "\n",
    "data_gen = image.ImageDataGenerator(\n",
    "    # define the preprocessing function that should be applied to all images\n",
    "    preprocessing_function=preprocess_input,\n",
    "    # fill_mode='nearest',\n",
    "    # rotation_range=20,\n",
    "    # width_shift_range=0.2,\n",
    "    # height_shift_range=0.2,\n",
    "    # horizontal_flip=True, \n",
    "    # zoom_range=0.2,\n",
    "    # shear_range=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a generator that returns batches of X and y arrays\n",
    "train_data_gen = data_gen.flow_from_directory(\n",
    "        directory='data/train',\n",
    "        class_mode=\"categorical\",\n",
    "        classes=classes,\n",
    "        batch_size=150,\n",
    "        target_size=(224, 224),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_gen = data_gen.flow_from_directory(\n",
    "        directory='data/validation/',\n",
    "        class_mode=\"categorical\",\n",
    "        classes=classes,\n",
    "        batch_size=150,\n",
    "        target_size=(224, 224),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Select the convolutional base / Pretrained network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Freeze the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Add your own dense layers on top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "K.clear_session()\n",
    "\n",
    "#1. Select the convolutional base / Pretrained network\n",
    "base_model = ResNet50(include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When loading a given model, the “include_top” argument can be set to False, in which case the fully-connected output layers of the model used to make predictions is not loaded, allowing a new output layer to be added and trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Freeze the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Freeze the weights in order to not retrain the loaded pre-trained model\n",
    "base_model.trainable= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Add your own dense layers on top, in our case we have only 2 classes to classify `phone/wallet`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of building CNN model from scratch, we are using ResNet50 and fine tuning it to fit to our dataset by editing the last few layers of our pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create your model with pretrained network as base model\n",
    "inputs = Input(shape=(224,224,3))\n",
    "\n",
    "base = base_model(inputs)\n",
    "\n",
    "# can also add additional cnn layers if necessary\n",
    "\n",
    "# dont forget to flatten out before the final layer\n",
    "flatten = GlobalAveragePooling2D()(base)\n",
    "\n",
    "outputs = Dense(2,activation='softmax')(flatten)\n",
    "\n",
    "model_tf = Model(inputs,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Compile and train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_tf.fit(train_data_gen,\n",
    "          verbose=2, # how the training log should get printed \n",
    "          epochs=10,\n",
    "          validation_data=val_data_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5. Use it to predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x = classes, height = model_tf.predict(img)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For remapping the index values of highest prediction probability to its respective class\n",
    "\n",
    "pred = model_tf.predict(img)\n",
    "\n",
    "preds_cls = list(train_data_gen.class_indices.keys())[list(train_data_gen.class_indices.values()).index(np.argmax(pred,axis=-1))]\n",
    "preds_cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6. Save your model for later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/wallet_phone.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "- Try out different pretrained models as base\n",
    "- Choose any [image classification dataset](https://www.kaggle.com/datasets?search=image) and build your CNN model (optional)\n",
    "    - Try building your CNN model from scratch\n",
    "    - Use transfer learning approach to train your CNN model\n",
    "\n",
    "- For running big CNN models with bigger datasets, sometimes your laptop hardware may not be sufficient \n",
    "    - You can use free cloud resources for training such models as they provide you with free GPU as well (GPU speeds up training)\n",
    "    - [Google Colab](https://colab.research.google.com/)\n",
    "    - [Kaggle kernel](https://www.kaggle.com/code) (click on `New notebook`, also you will need to verify phone number inorder to use GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the entire images and labels into arrays (alternate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's explore the data folder\n",
    "import os\n",
    "base_path = 'data/train/'\n",
    "\n",
    "# Let's define the classes\n",
    "classes = os.listdir(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " for class_ in classes:\n",
    "        print(class_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(base_path):\n",
    "    \"\"\"it loads all the image into X and the classes in y \"\"\"\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    classes = os.listdir(base_path)\n",
    "    for class_ in classes:\n",
    "        if class_!='.DS_Store':\n",
    "        \n",
    "            files = os.listdir(base_path+class_)\n",
    "            for file in files:\n",
    "                pic = image.load_img(path=base_path+class_+'/'+f'{file}',target_size=(224,224))\n",
    "                numpy_image = np.array(pic)\n",
    "                processed_image = preprocess_input(numpy_image)\n",
    "                X_list.append(processed_image)\n",
    "                y_list.append(class_)\n",
    "\n",
    "    X = np.array(X_list)\n",
    "    y = np.array(y_list)\n",
    "    \n",
    "    return X, y, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,classes= load_image(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {\"wallet\":0, \"phone\":1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map strings to binary labels\n",
    "y = np.vectorize(my_dict.get)(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf __MACOSX\n",
    "!rm -rf data/\n",
    "!rm -rf .DS_Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional links\n",
    "\n",
    "\n",
    "https://keras.io/guides/transfer_learning/\n",
    "\n",
    "https://www.tensorflow.org/tutorials/images/data_augmentation\n",
    "\n",
    "\n",
    "\n",
    "[Guide for Transfer learning](https://neptune.ai/blog/transfer-learning-guide-examples-for-images-and-text-in-keras)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
